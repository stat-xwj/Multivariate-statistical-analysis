train_table = table(train_predict, train$type)
sum(diag(train_table))/sum(train_table)
X_test = as.matrix(cbind(rep(1, nrow(test)), test[, -p]))
test_predict = exp(X_test %*% w)/(1+exp(X_test %*% w))
test_predict = ifelse(test_predict>0.5, 1, 0)
test_table = table(test_predict, test$type)
sum(diag(test_table))/sum(test_table)
w = logisticGradientDescent(input_data = train, maxIterion = 1e5, epslion = 1e-5, learningRate = 0.0001)
# 评估准确率
p = ncol(train)
X_train = as.matrix(cbind(rep(1, nrow(train)), train[, -p]))
train_predict = exp(X_train %*% w)/(1+exp(X_train %*% w))
train_predict = ifelse(train_predict>0.5, 1, 0)
train_table = table(train_predict, train$type)
sum(diag(train_table))/sum(train_table)
X_test = as.matrix(cbind(rep(1, nrow(test)), test[, -p]))
test_predict = exp(X_test %*% w)/(1+exp(X_test %*% w))
test_predict = ifelse(test_predict>0.5, 1, 0)
test_table = table(test_predict, test$type)
sum(diag(test_table))/sum(test_table)
cat('train accuracy:', sum(diag(train_table)/sum(train_table)), '\n',
'test accuracy:', sum(diag(test_table)/sum(test_table)))
w = logisticNewton(input_data = train, maxIterion = 1e5, epslion = 1e-5)
#和使用库函数得到的结果完全一致。
logistic.model$coefficients
library(MASS)
set.seed(1)
Sig = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
library(MASS)
set.seed(1)
mu = c(0, 2)
Sig = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
biv1=mvrnorm(n, mu, Sig);colnames(biv1)=c("X","Y")
n = 1000
set.seed(1)
mu = c(0, 2)
Sig = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
biv1=mvrnorm(n, mu, Sig);colnames(biv1)=c("X","Y")
Sig = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
biv1=mvrnorm(n, mu, Sig);colnames(biv1)=c("X","Y")
dataEllipse(biv1[, 1], biv1[, 2], levels = 0.95)
library(car)
dataEllipse(biv1[, 1], biv1[, 2], levels = 0.95)
points(t(mu), col = ’red’, pch = 8)
points(t(mu), col = 'red', pch = 8)
n1 = 1000
set.seed(1)
mu2 = c(2, 0)
Sig2 = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
biv1=mvrnorm(n, mu, Sig);colnames(biv1)=c("X","Y")
dataEllipse(biv2[, 1], biv2[, 2], levels = 0.95)
points(t(mu2), col = 'red', pch = 8)
n1 = 1000
set.seed(1)
mu2 = c(2, 0)
Sig2 = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
biv2=mvrnorm(n, mu, Sig);colnames(biv1)=c("X","Y")
dataEllipse(biv2[, 1], biv2[, 2], levels = 0.95)
points(t(mu2), col = 'red', pch = 8)
colMeans(biv1)[1]
colMeans(biv1)
Sig[1, 1]
n = n1+n2
p = 2
alpha = 0.05
delta1.Low = colMeans(biv1)[1]-colMeans(biv2)[1] + sqrt((n1+n2)/(n1*n2))*sqrt(Sig[1, 1])*sqrt((2-1)*qf(1-alpha/p, 2-1, n-2))
n2 = 1000
n = n1+n2
p = 2
alpha = 0.05
delta1.Low = colMeans(biv1)[1]-colMeans(biv2)[1] + sqrt((n1+n2)/(n1*n2))*sqrt(Sig[1, 1])*sqrt((2-1)*qf(1-alpha/p, 2-1, n-2))
delta1.Low
delta1.L = colMeans(biv1)[1]-colMeans(biv2)[1] + sqrt((n1+n2)/(n1*n2))*sqrt(Sig[1, 1])*sqrt((2-1)*qf(1-alpha/p, 2-1, n-2))
delta1.L = colMeans(biv1)[1]-colMeans(biv2)[1] - sqrt((n1+n2)/(n1*n2))*sqrt(Sig[1, 1])*sqrt((2-1)*qf(1-alpha/p, 2-1, n-2))
delta1.U = colMeans(biv1)[1]-colMeans(biv2)[1] + sqrt((n1+n2)/(n1*n2))*sqrt(Sig[1, 1])*sqrt((2-1)*qf(1-alpha/p, 2-1, n-2))
delta1.L
delta1.U
delta2.L = colMeans(biv1)[2]-colMeans(biv2)[2] - sqrt((n1+n2)/(n1*n2))*sqrt(Sig[2, 2])*sqrt((2-1)*qf(1-alpha/p, 2-1, n-2))
delta2.U = colMeans(biv1)[2]-colMeans(biv2)[2] + sqrt((n1+n2)/(n1*n2))*sqrt(Sig[2, 2])*sqrt((2-1)*qf(1-alpha/p, 2-1, n-2))
delta2.L
delta2.U
n1 = 1000
set.seed(1)
mu1 = c(1, 2)
Sig = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
biv1=mvrnorm(n1, mu, Sig);colnames(biv1)=c("X","Y")
dataEllipse(biv1[, 1], biv1[, 2], levels = 0.95)
Sig = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
biv1=mvrnorm(n1, mu1, Sig);colnames(biv1)=c("X","Y")
dataEllipse(biv1[, 1], biv1[, 2], levels = 0.95)
points(t(mu1), col = 'red', pch = 8)
n2 = 1000
set.seed(1)
mu2 = c(3, 5)
Sig = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
biv2=mvrnorm(n2, mu2, Sig);colnames(biv1)=c("X","Y")
dataEllipse(biv2[, 1], biv2[, 2], levels = 0.95)
points(t(mu2), col = 'red', pch = 8)
dataEllipse(biv1[, 1], biv1[, 2], levels = 0.95)
n = n1+n2
p = 2
alpha = 0.05
delta1.L = colMeans(biv1)[1]-colMeans(biv2)[1] - sqrt((n1+n2)/(n1*n2))*sqrt(Sig[1, 1])*sqrt((2-1)*qf(1-alpha/p, 2-1, n-2))
delta1.U = colMeans(biv1)[1]-colMeans(biv2)[1] + sqrt((n1+n2)/(n1*n2))*sqrt(Sig[1, 1])*sqrt((2-1)*qf(1-alpha/p, 2-1, n-2))
delta2.L = colMeans(biv1)[2]-colMeans(biv2)[2] - sqrt((n1+n2)/(n1*n2))*sqrt(Sig[2, 2])*sqrt((2-1)*qf(1-alpha/p, 2-1, n-2))
delta2.U = colMeans(biv1)[2]-colMeans(biv2)[2] + sqrt((n1+n2)/(n1*n2))*sqrt(Sig[2, 2])*sqrt((2-1)*qf(1-alpha/p, 2-1, n-2))
delta1.L
delta1.U
delta2.L
delta2.U
# 差值图
dataEllipse(biv1[, 1]-biv2[, 1], biv1[, 2]-biv2[, 2], levels = 0.95)
iv1[, 1]-biv2[, 1]
biv1[, 1]-biv2[, 1]
biv1
biv2[, 1]
biv2[, 1]
(delta1.L, delta1.U)
c(delta1.L, delta1.U)
c(delta2.L, delta2.U)
# 基于Bonferroni
delta1.L = colMeans(biv1)[1]-colMeans(biv2)[1] - sqrt((n1+n2)/(n1*n2))*sqrt(Sig[1, 1])*qt(1-alpha/(2*(2-1)*p), n-2)
delta1.L
delta1.U = colMeans(biv1)[1]-colMeans(biv2)[1] + sqrt((n1+n2)/(n1*n2))*sqrt(Sig[1, 1])*qt(1-alpha/(2*(2-1)*p), n-2)
delta1.U
delta2.L = colMeans(biv1)[2]-colMeans(biv2)[2] - sqrt((n1+n2)/(n1*n2))*sqrt(Sig[2, 2])*qt(1-alpha/(2*(2-1)*p), n-2)
delta2.U = colMeans(biv1)[2]-colMeans(biv2)[2] + sqrt((n1+n2)/(n1*n2))*sqrt(Sig[2, 2])*qt(1-alpha/(2*(2-1)*p), n-2)
c(delta2.L, delta2.U)
S1 = matrix(c(120.00, -16.304, -16.304, 17.792), nrow = 2, ncol = 2)
S1
S1 = matrix(c(81.796, 32.098, 32.098, 53.801), nrow = 2, ncol = 2)
V1 = (n1-1)*S1
n^(p*n/2)
n^(p*n/2)/(n1^(p*n1/2)*n2^(p*n2/2))
(n1^(p*n1/2)*n2^(p*n2/2))
log(n^(p*n/2))
n
n1 = 16; n2 = 11
k = 2
p = 2
n = n1+n2
xbar = c(9.82, 15.06); ybar = c(13.05, 22.57)
S1 = matrix(c(120.00, -16.304, -16.304, 17.792), nrow = 2, ncol = 2)
S1 = matrix(c(81.796, 32.098, 32.098, 53.801), nrow = 2, ncol = 2)
V1 = (n1-1)*S1
V2 = (n2-1)*S2
S1 = matrix(c(120.00, -16.304, -16.304, 17.792), nrow = 2, ncol = 2)
S2 = matrix(c(81.796, 32.098, 32.098, 53.801), nrow = 2, ncol = 2)
V1 = (n1-1)*S1
V2 = (n2-1)*S2
n^(p*n/2)/(n1^(p*n1/2)*n2^(p*n2/2))
det(V1)^(n1/2)*det(V2)^(n2/2)
n^(p*n/2)/(n1^(p*n1/2)*n2^(p*n2/2)) * det(V1)^(n1/2)*det(V2)^(n2/2)/(det(V1+V2)^(n/2))
-2*log(lambda)
lambda = n^(p*n/2)/(n1^(p*n1/2)*n2^(p*n2/2)) * det(V1)^(n1/2)*det(V2)^(n2/2)/(det(V1+V2)^(n/2))
-2*log(lambda)
df = (2-1)*p*(p+1)/2
pchisq(kafang, df)
kafang = -2*log(lambda)
df = (2-1)*p*(p+1)/2
pchisq(kafang, df)
1-pchisq(kafang, df)
# 修正后
lambda = (n-2)^(p*(n-2)/2)/((n1-1)^(p*(n1-1)/2)*(n2-1)^(p*(n2-1)/2)) * det(V1)^((n1-1)/2)*det(V2)^((n2-1)/2)/(det(V1+V2)^((n-2)/2))
lambda
kafang = -2*log(lambda)
k
rho = ((2*p^2+3^p-1)/(6*(p+1)*(k-1)))*(1/(n1-1)+1/(n2-1)-1/(n-k))
rho
kafang = -2*rho*log(lambda)
df = (2-1)*p*(p+1)/2
1-pchisq(kafang, df)
rho
rho = ((2*p^2+3*p-1)/(6*(p+1)*(k-1)))*(1/(n1-1)+1/(n2-1)-1/(n-k))
kafang = -2*rho*log(lambda)
df = (2-1)*p*(p+1)/2
1-pchisq(kafang, df)
# 修正后
lambda = (n-k)^(p*(n-k)/2)/((n1-1)^(p*(n1-1)/2)*(n2-1)^(p*(n2-1)/2)) * det(V1)^((n1-1)/2)*det(V2)^((n2-1)/2)/(det(V1+V2)^((n-k)/2))
rho = ((2*p^2+3*p-1)/(6*(p+1)*(k-1)))*(1/(n1-1)+1/(n2-1)-1/(n-k))
kafang = -2*rho*log(lambda)
df = (2-1)*p*(p+1)/2
1-pchisq(kafang, df)
rho = 1-((2*p^2+3*p-1)/(6*(p+1)*(k-1)))*(1/(n1-1)+1/(n2-1)-1/(n-k))
kafang = -2*rho*log(lambda)
df = (2-1)*p*(p+1)/2
1-pchisq(kafang, df)
啊=1
啊
###################################### 8
n = 1000
set.seed(1)
mu = c(1, 2)
Sig = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
data = mvrnorm(n, mu, Sig);colnames(biv1)=c("X","Y")
trace(V)
# 计算修正后的
V = (n-1)*var(data)
V
trace(V)
###################################### 8
n = 1000
set.seed(1)
mu = c(1, 2)
sigma = 1.1
Sig0 = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
data = mvrnorm(n, mu, sigma^2*Sig0);colnames(biv1)=c("X","Y")
solve(Sig0)
solve(Sig0) %*% V
lambda = det(solve(Sig0) %*% V)^((n-1)/2)/((sum(diag(solve(Sig0) %*% V))/p)^((n-1)*p/2))
det(solve(Sig0) %*% V)
###################################### 8
n = 1000
set.seed(1)
mu = c(0.1, 0.2)
sigma = 1.1
Sig0 = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
data = mvrnorm(n, mu, sigma^2*Sig0);colnames(biv1)=c("X","Y")
# 计算修正后的
V = (n-1)*var(data)
lambda = det(solve(Sig0) %*% V)^((n-1)/2)/((sum(diag(solve(Sig0) %*% V))/p)^((n-1)*p/2))
det(solve(Sig0)
)
det(solve(Sig0) %*% V)
det(solve(Sig0) %*% V)^100
det(solve(Sig0) %*% V)^10
-(n-1)*log(det(solve(Sig0) %*% V))
kafang = -(n-1)*log(det(solve(Sig0) %*% V))+(n-1)*p*log(sum(diag(det(solve(Sig0) %*% V)))/p)
(n-1)*p*log(sum(diag(det(solve(Sig0) %*% V)))/p)
log(sum(diag(det(solve(Sig0) %*% V)))/p)
sum(diag(det(solve(Sig0) %*% V)))/p
sum(diag(det(solve(Sig0) %*% V)))
det(solve(Sig0) %*% V)
sum(diag(solve(Sig0) %*% V))
kafang = -(n-1)*log(det(solve(Sig0) %*% V))+(n-1)*p*log(sum(diag(solve(Sig0) %*% V))/p)
df = p*(p+1)/2-1
p = 1-pchisq(kafang, df)
p
###################################### 8
n = 1000
set.seed(1)
mu = c(0.1, 0.2)
sigma = 1.1
Sig0 = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
# Sig = sigma^2*Sig0
Sig = matrix(c(1, 0.9, 0.9, 1), 2, 2)
data = mvrnorm(n, mu, Sig);colnames(biv1)=c("X","Y")
# 计算修正后的
V = (n-1)*var(data)
kafang = -(n-1)*log(det(solve(Sig0) %*% V))+(n-1)*p*log(sum(diag(solve(Sig0) %*% V))/p)
df = p*(p+1)/2-1
p = 1-pchisq(kafang, df)
df
###################################### 8
p = 2
n = 1000
set.seed(1)
mu = c(0.1, 0.2)
sigma = 1.1
Sig0 = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
# Sig = sigma^2*Sig0
Sig = matrix(c(1, 0.9, 0.9, 1), 2, 2)
data = mvrnorm(n, mu, Sig);colnames(biv1)=c("X","Y")
# 计算修正后的
V = (n-1)*var(data)
kafang = -(n-1)*log(det(solve(Sig0) %*% V))+(n-1)*p*log(sum(diag(solve(Sig0) %*% V))/p)
df = p*(p+1)/2-1
p = 1-pchisq(kafang, df)
p
p = 2
n = 1000
set.seed(1)
mu = c(0.1, 0.2)
sigma = 1.1
Sig0 = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
# Sig = sigma^2*Sig0
Sig = matrix(c(1, 0.9, 0.9, 1), 2, 2)
data = mvrnorm(n, mu, Sig);colnames(biv1)=c("X","Y")
# 计算修正后的
V = (n-1)*var(data)
# lambda = det(solve(Sig0) %*% V)^((n-1)/2)/((sum(diag(solve(Sig0) %*% V))/p)^((n-1)*p/2))
# 直接计算内存会溢出
kafang = -(n-1)*log(det(solve(Sig0) %*% V))+(n-1)*p*log(sum(diag(solve(Sig0) %*% V))/p)
df = p*(p+1)/2-1
pvalue = 1-pchisq(kafang, df)
pvalue
# lambda = det(solve(Sig0) %*% V)^((n-1)/2)/((sum(diag(solve(Sig0) %*% V))/p)^((n-1)*p/2))
# 直接计算内存会溢出
kafang
kafang
results = c(length(0))
N = 1000
p = 2
mu = c(0.1, 0.2)
sigma = 1.1
Sig0 = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
# Sig = sigma^2*Sig0
Sig = matrix(c(1, 0.9, 0.9, 1), 2, 2)
results = c(length(0))
for (n in 5:1000) {
pvalue = 0
for (i in 1:N) {
set.seed(i)
data = mvrnorm(n, mu, Sig);colnames(biv1)=c("X","Y")
# 计算修正后的
V = (n-1)*var(data)
# lambda = det(solve(Sig0) %*% V)^((n-1)/2)/((sum(diag(solve(Sig0) %*% V))/p)^((n-1)*p/2))
# 直接计算内存会溢出
kafang = -(n-1)*log(det(solve(Sig0) %*% V))+(n-1)*p*log(sum(diag(solve(Sig0) %*% V))/p)
df = p*(p+1)/2-1
pvalue = pvalue + 1-pchisq(kafang, df)
}
results[n-4] = pvalue/N
}
results
plot(results)
plot(results, type='o')
plot(results)
N = 1000
p = 2
mu = c(0.1, 0.2)
sigma = 1.1
Sig0 = matrix(c(1 ,0.7, 0.7, 1), 2, 2)
Sig = sigma^2*Sig0
# Sig = matrix(c(1, 0.9, 0.9, 1), 2, 2)
results = c(length(0))
for (n in 5:1000) {
pvalue = 0
for (i in 1:N) {
set.seed(i)
data = mvrnorm(n, mu, Sig);colnames(biv1)=c("X","Y")
# 计算修正后的
V = (n-1)*var(data)
# lambda = det(solve(Sig0) %*% V)^((n-1)/2)/((sum(diag(solve(Sig0) %*% V))/p)^((n-1)*p/2))
# 直接计算内存会溢出
kafang = -(n-1)*log(det(solve(Sig0) %*% V))+(n-1)*p*log(sum(diag(solve(Sig0) %*% V))/p)
df = p*(p+1)/2-1
pvalue = pvalue + 1-pchisq(kafang, df)
}
results[n-4] = pvalue/N
}
plot(results)
n1 = 16; n2 = 11
k = 2
p = 2
n = n1+n2
xbar = c(9.82, 15.06); ybar = c(13.05, 22.57)
S1 = matrix(c(120.00, -16.304, -16.304, 17.792), nrow = 2, ncol = 2)
S2 = matrix(c(81.796, 32.098, 32.098, 53.801), nrow = 2, ncol = 2)
V1 = (n1-1)*S1
V2 = (n2-1)*S2
lambda = n^(p*n/2)/(n1^(p*n1/2)*n2^(p*n2/2)) * det(V1)^(n1/2)*det(V2)^(n2/2)/(det(V1+V2)^(n/2))
kafang = -2*log(lambda)
df = (2-1)*p*(p+1)/2
1-pchisq(kafang, df)
# 修正后
lambda = (n-k)^(p*(n-k)/2)/((n1-1)^(p*(n1-1)/2)*(n2-1)^(p*(n2-1)/2)) * det(V1)^((n1-1)/2)*det(V2)^((n2-1)/2)/(det(V1+V2)^((n-k)/2))
rho = 1-((2*p^2+3*p-1)/(6*(p+1)*(k-1)))*(1/(n1-1)+1/(n2-1)-1/(n-k))
kafang = -2*rho*log(lambda)
df = (2-1)*p*(p+1)/2
1-pchisq(kafang, df)
# discriminiant
# 距离判别
setwd('C:\\Users\\xiawenjun\\Desktop\\助教\\Multivariate-statistical-analysis\\discriminant')
source('discriminiant.distance.R')
mahalanobis
# discriminiant
# 距离判别
setwd('C:\\Users\\xiawenjun\\Desktop\\助教\\Multivariate-statistical-analysis\\discriminant')
source('discriminiant.distance.R')
classX1<-data.frame(
x1=c(6.60,  6.60,  6.10,  6.10,  8.40,  7.2,   8.40,  7.50,
7.50,  8.30,  7.80,  7.80),
x2=c(39.00, 39.00, 47.00, 47.00, 32.00,  6.0, 113.00, 52.00,
52.00,113.00,172.00,172.00),
x3=c(1.00,  1.00,  1.00,  1.00,  2.00,  1.0,   3.50,  1.00,
3.50,  0.00,  1.00,  1.50),
x4=c(6.00,  6.00,  6.00,  6.00,  7.50,  7.0,   6.00,  6.00,
7.50,  7.50,  3.50,  3.00),
x5=c(6.00, 12.00,  6.00, 12.00, 19.00, 28.0,  18.00, 12.00,
6.00, 35.00, 14.00, 15.00),
x6=c(0.12,  0.12,  0.08,  0.08,  0.35,  0.3,   0.15,  0.16,
0.16,  0.12,  0.21,  0.21),
x7=c(20.00, 20.00, 12.00, 12.00, 75.00, 30.0,  75.00, 40.00,
40.00,180.00, 45.00, 45.00)
)
classX2<-data.frame(
x1=c(8.40,  8.40,  8.40,  6.3, 7.00,  7.00,  7.00,  8.30,
8.30,   7.2,   7.2,  7.2, 5.50,  8.40,  8.40,  7.50,
7.50,  8.30,  8.30, 8.30, 8.30,  7.80,  7.80),
x2=c(32.0 ,32.00, 32.00, 11.0, 8.00,  8.00,  8.00, 161.00,
161.0,   6.0,   6.0,  6.0, 6.00,113.00,113.00,  52.00,
52.00, 97.00, 97.00,89.00,56.00,172.00,283.00),
x3=c(1.00,  2.00,  2.50,  4.5, 4.50,  6.00,  1.50,  1.50,
0.50,   3.5,   1.0,  1.0, 2.50,  3.50,  3.50,  1.00,
1.00,  0.00,  2.50, 0.00, 1.50,  1.00,  1.00),
x4=c(5.00,  9.00,  4.00,  7.5, 4.50,  7.50,  6.00,  4.00,
2.50,   4.0,   3.0,  6.0, 3.00,  4.50,  4.50,  6.00,
7.50,  6.00,  6.00, 6.00, 6.00,  3.50,  4.50),
x5=c(4.00, 10.00, 10.00,  3.0, 9.00,  4.00,  1.00,  4.00,
1.00,  12.0,   3.0,  5.0, 7.00,  6.00,  8.00,  6.00,
8.00,  5.00,  5.00,10.00,13.00,  6.00,  6.00),
x6=c(0.35,  0.35,  0.35,  0.2, 0.25,  0.25,  0.25,  0.08,
0.08,  0.30,   0.3,  0.3, 0.18,  0.15,  0.15,  0.16,
0.16,  0.15,  0.15, 0.16, 0.25,  0.21,  0.18),
x7=c(75.00, 75.00, 75.00,  15.0, 30.00, 30.00, 30.00, 70.00,
70.00,  30.0,  30.0,  30.0, 18.00, 75.00, 75.00, 40.00,
40.00,180.00,180.00,180.00,180.00, 45.00, 45.00)
)
# discriminiant.distance
results = discriminiant.distance(classX1, classX2, var.equal=TRUE)
# discriminiant
# 距离判别
setwd('C:\\Users\\xiawenjun\\Desktop\\助教\\Multivariate-statistical-analysis\\discriminant')
source('discriminiant.distance.R')
classX1<-data.frame(
x1=c(6.60,  6.60,  6.10,  6.10,  8.40,  7.2,   8.40,  7.50,
7.50,  8.30,  7.80,  7.80),
x2=c(39.00, 39.00, 47.00, 47.00, 32.00,  6.0, 113.00, 52.00,
52.00,113.00,172.00,172.00),
x3=c(1.00,  1.00,  1.00,  1.00,  2.00,  1.0,   3.50,  1.00,
3.50,  0.00,  1.00,  1.50),
x4=c(6.00,  6.00,  6.00,  6.00,  7.50,  7.0,   6.00,  6.00,
7.50,  7.50,  3.50,  3.00),
x5=c(6.00, 12.00,  6.00, 12.00, 19.00, 28.0,  18.00, 12.00,
6.00, 35.00, 14.00, 15.00),
x6=c(0.12,  0.12,  0.08,  0.08,  0.35,  0.3,   0.15,  0.16,
0.16,  0.12,  0.21,  0.21),
x7=c(20.00, 20.00, 12.00, 12.00, 75.00, 30.0,  75.00, 40.00,
40.00,180.00, 45.00, 45.00)
)
classX2<-data.frame(
x1=c(8.40,  8.40,  8.40,  6.3, 7.00,  7.00,  7.00,  8.30,
8.30,   7.2,   7.2,  7.2, 5.50,  8.40,  8.40,  7.50,
7.50,  8.30,  8.30, 8.30, 8.30,  7.80,  7.80),
x2=c(32.0 ,32.00, 32.00, 11.0, 8.00,  8.00,  8.00, 161.00,
161.0,   6.0,   6.0,  6.0, 6.00,113.00,113.00,  52.00,
52.00, 97.00, 97.00,89.00,56.00,172.00,283.00),
x3=c(1.00,  2.00,  2.50,  4.5, 4.50,  6.00,  1.50,  1.50,
0.50,   3.5,   1.0,  1.0, 2.50,  3.50,  3.50,  1.00,
1.00,  0.00,  2.50, 0.00, 1.50,  1.00,  1.00),
x4=c(5.00,  9.00,  4.00,  7.5, 4.50,  7.50,  6.00,  4.00,
2.50,   4.0,   3.0,  6.0, 3.00,  4.50,  4.50,  6.00,
7.50,  6.00,  6.00, 6.00, 6.00,  3.50,  4.50),
x5=c(4.00, 10.00, 10.00,  3.0, 9.00,  4.00,  1.00,  4.00,
1.00,  12.0,   3.0,  5.0, 7.00,  6.00,  8.00,  6.00,
8.00,  5.00,  5.00,10.00,13.00,  6.00,  6.00),
x6=c(0.35,  0.35,  0.35,  0.2, 0.25,  0.25,  0.25,  0.08,
0.08,  0.30,   0.3,  0.3, 0.18,  0.15,  0.15,  0.16,
0.16,  0.15,  0.15, 0.16, 0.25,  0.21,  0.18),
x7=c(75.00, 75.00, 75.00,  15.0, 30.00, 30.00, 30.00, 70.00,
70.00,  30.0,  30.0,  30.0, 18.00, 75.00, 75.00, 40.00,
40.00,180.00,180.00,180.00,180.00, 45.00, 45.00)
)
# discriminiant.distance
results = discriminiant.distance(classX1, classX2, var.equal=TRUE)
discriminiant.distance
# discriminiant.distance
results = discriminiant.distance(classX1, classX2, var.equal=TRUE)
c(rep(1, nrow(classX1)),rep(2, nrow(classX2)))
table(results, c(rep(1, nrow(classX1)),rep(2, nrow(classX2))))
results = discriminiant.distance(classX1, classX2)
table(results, c(rep(1, nrow(classX1)),rep(2, nrow(classX2))))
# 多分类
source("distinguish.distance.R")
X<-iris[,1:4]
G<-gl(3,50)
X<-iris[,1:4]
G<-gl(3,50)
G
results = distinguish.distance(X,G)
results = distinguish.distance(X,G)
table(results, G)
results = distinguish.distance(X,G,var.equal = T)
table(results, G)
# bayes 判别
TrnX1<-matrix(
c(24.8, 24.1, 26.6, 23.5, 25.5, 27.4,
-2.0, -2.4, -3.0, -1.9, -2.1, -3.1),
ncol=2)
TrnX2<-matrix(
c(22.1, 21.6, 22.0, 22.8, 22.7, 21.5, 22.1, 21.4,
-0.7, -1.4, -0.8, -1.6, -1.5, -1.0, -1.2, -1.3),
ncol=2)
source("discriminiant.bayes.R")
#### 样本协方差相同
results = discriminiant.bayes(TrnX1, TrnX2, rate=8/6, var.equal=TRUE)
#### 样本协方差相同
results = discriminiant.bayes(TrnX1, TrnX2, rate=8/6, var.equal=TRUE)
table(results, c(rep(1, nrow(TrnX1)),rep(2, nrow(TrnX2))))
#### 样本协方差相同
results = discriminiant.bayes(TrnX1, TrnX2, rate=8/6)
table(results, c(rep(1, nrow(TrnX1)),rep(2, nrow(TrnX2))))
# 多分类bayes
X<-iris[,1:4]
G<-gl(3,50)
source("distinguish.bayes.R")
results = distinguish.bayes(X,G)
results = distinguish.bayes(X,G)
table(results, G)
results = distinguish.bayes(X,G, var.equal = T)
table(results, G)
# fisher判别
# 对第一个例子进行fisher判别
source("discriminiant.fisher.R")
results = discriminiant.fisher(classX1, classX2)
table(results, c(rep(1, nrow(classX1)),rep(2, nrow(classX2))))
# fisher判别
# 对第一个例子进行fisher判别
source("discriminiant.fisher.R")
results = discriminiant.fisher(classX1, classX2)
table(results, c(rep(1, nrow(classX1)),rep(2, nrow(classX2))))
